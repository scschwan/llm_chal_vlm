"""
RAG (Retrieval-Augmented Generation) ë§¤ë‹ˆì €
LangChain ê¸°ë°˜ PDF ë§¤ë‰´ì–¼ ê²€ìƒ‰
"""

from __future__ import annotations
from pathlib import Path
from typing import List, Dict, Optional
import re

# LangChain imports
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.schema import Document


class RAGManager:
    """PDF ë§¤ë‰´ì–¼ RAG ê´€ë¦¬ì"""
    
    def __init__(
        self,
        pdf_path: str | Path,
        embedding_model: str = "jhgan/ko-sbert-nli",
        vector_store_path: Optional[str | Path] = None,
        device: str = "cuda",
        verbose: bool = True
    ):
        """
        Args:
            pdf_path: PDF ë§¤ë‰´ì–¼ ê²½ë¡œ
            embedding_model: ì„ë² ë”© ëª¨ë¸ëª…
            vector_store_path: ë²¡í„° DB ìºì‹œ ê²½ë¡œ (Noneì´ë©´ ë§¤ë²ˆ ìƒˆë¡œ êµ¬ì¶•)
            device: ë””ë°”ì´ìŠ¤ (cuda/cpu)
            verbose: ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
        """
        self.pdf_path = Path(pdf_path)
        self.vector_store_path = Path(vector_store_path) if vector_store_path else None
        self.device = device
        self.verbose = verbose
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        if self.verbose:
            print(f"ğŸ”¤ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {embedding_model}")
        
        self.embeddings = HuggingFaceEmbeddings(
            model_name=embedding_model,
            model_kwargs={'device': self.device}
        )
        
        # ë²¡í„° DB ë¡œë“œ ë˜ëŠ” êµ¬ì¶•
        self.vectorstore = self._load_or_build_vectorstore()
        
        if self.verbose:
            print("âœ… RAG ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_or_build_vectorstore(self) -> FAISS:
        """ë²¡í„° DB ë¡œë“œ ë˜ëŠ” ì‹ ê·œ êµ¬ì¶•"""
        # ìºì‹œ ê²½ë¡œê°€ ìˆê³  ì¡´ì¬í•˜ë©´ ë¡œë“œ
        if self.vector_store_path and self.vector_store_path.exists():
            if self.verbose:
                print(f"ğŸ“‚ ë²¡í„° DB ë¡œë“œ ì¤‘: {self.vector_store_path}")
            
            return FAISS.load_local(
                str(self.vector_store_path),
                self.embeddings
            )
        
        # ì‹ ê·œ êµ¬ì¶•
        if self.verbose:
            print(f"ğŸ“„ PDF ë¡œë“œ ì¤‘: {self.pdf_path}")
        
        documents = self._load_and_parse_pdf()
        
        if self.verbose:
            print(f"ğŸ”¨ ë²¡í„° DB êµ¬ì¶• ì¤‘... ({len(documents)}ê°œ ë¬¸ì„œ)")
        
        vectorstore = FAISS.from_documents(documents, self.embeddings)
        
        # ìºì‹œ ì €ì¥
        if self.vector_store_path:
            self.vector_store_path.parent.mkdir(parents=True, exist_ok=True)
            vectorstore.save_local(str(self.vector_store_path))
            if self.verbose:
                print(f"ğŸ’¾ ë²¡í„° DB ì €ì¥ ì™„ë£Œ: {self.vector_store_path}")
        
        return vectorstore
    
    def _load_and_parse_pdf(self) -> List[Document]:
        """
        PDF ë¡œë“œ ë° ë¶ˆëŸ‰ë³„ ì„¹ì…˜ íŒŒì‹±
        
        ê° ë¶ˆëŸ‰ì„ ë…ë¦½ëœ Documentë¡œ ìƒì„±í•˜ì—¬
        ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
        """
        # PDF ë¡œë“œ
        loader = PyPDFLoader(str(self.pdf_path))
        raw_docs = loader.load()
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        full_text = "\n".join([doc.page_content for doc in raw_docs])
        
        # ë¶ˆëŸ‰ë³„ ì„¹ì…˜ ë¶„ë¦¬
        sections = self._split_by_defect_sections(full_text)
        
        # Document ê°ì²´ ìƒì„±
        documents = []
        for section in sections:
            # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            defect_name = section.get("defect", "unknown")
            
            # ë°œìƒ ì›ì¸ Document
            if section.get("cause"):
                documents.append(Document(
                    page_content=section["cause"],
                    metadata={
                        "defect": defect_name,
                        "section": "ì›ì¸",
                        "source": str(self.pdf_path)
                    }
                ))
            
            # ì¡°ì¹˜ ê°€ì´ë“œ Document
            if section.get("action"):
                documents.append(Document(
                    page_content=section["action"],
                    metadata={
                        "defect": defect_name,
                        "section": "ì¡°ì¹˜",
                        "source": str(self.pdf_path)
                    }
                ))
        
        return documents
    
    def _split_by_defect_sections(self, text: str) -> List[Dict[str, str]]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ‰ë³„ ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬
        
        íŒ¨í„´:
        â‘  hole (ê¸°ê³µ)
        ë°œìƒ ì›ì¸
        ...
        ì¡°ì¹˜ ê°€ì´ë“œ
        ...
        """
        sections = []
        
        # ë¶ˆëŸ‰ ì œëª© íŒ¨í„´: â‘  hole (ê¸°ê³µ)
        defect_pattern = r'[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\s+(\w+)\s*\(([^)]+)\)'
        
        # ë¶ˆëŸ‰ë³„ë¡œ ë¶„ë¦¬
        defect_matches = list(re.finditer(defect_pattern, text))
        
        for i, match in enumerate(defect_matches):
            defect_en = match.group(1).strip()
            defect_ko = match.group(2).strip()
            
            # ì„¹ì…˜ ì‹œì‘/ë ìœ„ì¹˜
            start_pos = match.end()
            end_pos = defect_matches[i+1].start() if i+1 < len(defect_matches) else len(text)
            
            section_text = text[start_pos:end_pos]
            
            # "ë°œìƒ ì›ì¸"ê³¼ "ì¡°ì¹˜ ê°€ì´ë“œ" ë¶„ë¦¬
            cause_match = re.search(r'ë°œìƒ ì›ì¸(.*?)ì¡°ì¹˜ ê°€ì´ë“œ', section_text, re.DOTALL)
            action_match = re.search(r'ì¡°ì¹˜ ê°€ì´ë“œ(.*?)(?=(?:[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]|$))', section_text, re.DOTALL)
            
            sections.append({
                "defect": defect_en,
                "defect_ko": defect_ko,
                "cause": cause_match.group(1).strip() if cause_match else "",
                "action": action_match.group(1).strip() if action_match else ""
            })
        
        return sections
    
    def search_defect_manual(
        self,
        product: str,
        defect_en: str,
        keywords: List[str],
        top_k: int = 3
    ) -> Dict[str, List[str]]:
        """
        ë¶ˆëŸ‰ ë§¤ë‰´ì–¼ ê²€ìƒ‰
        
        Args:
            product: ì œí’ˆëª… (í˜„ì¬ëŠ” ë¯¸ì‚¬ìš©, ì¶”í›„ ì œí’ˆë³„ PDF ì§€ì› ì‹œ í™œìš©)
            defect_en: ì˜ì–´ ë¶ˆëŸ‰ëª…
            keywords: ê²€ìƒ‰ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            top_k: ìƒìœ„ Kê°œ ê²°ê³¼
        
        Returns:
            {"ì›ì¸": [...], "ì¡°ì¹˜": [...]}
        """
        # í‚¤ì›Œë“œ ì¡°í•© ì¿¼ë¦¬ ìƒì„±
        query = " ".join(keywords)
        
        if self.verbose:
            print(f"ğŸ” ë§¤ë‰´ì–¼ ê²€ìƒ‰: {query}")
        
        # ë²¡í„° ê²€ìƒ‰
        results = self.vectorstore.similarity_search(
            query,
            k=top_k * 2  # ì›ì¸/ì¡°ì¹˜ ê°ê° í•„ìš”í•˜ë¯€ë¡œ ë” ë§ì´ ê²€ìƒ‰
        )
        
        # ì„¹ì…˜ë³„ ë¶„ë¦¬
        cause_docs = [
            doc.page_content for doc in results 
            if doc.metadata.get("section") == "ì›ì¸"
        ]
        action_docs = [
            doc.page_content for doc in results 
            if doc.metadata.get("section") == "ì¡°ì¹˜"
        ]
        
        return {
            "ì›ì¸": cause_docs[:top_k],
            "ì¡°ì¹˜": action_docs[:top_k]
        }
    
    def rebuild_index(self):
        """ë²¡í„° DB ì¬êµ¬ì¶•"""
        if self.verbose:
            print("ğŸ”„ ë²¡í„° DB ì¬êµ¬ì¶• ì¤‘...")
        
        documents = self._load_and_parse_pdf()
        self.vectorstore = FAISS.from_documents(documents, self.embeddings)
        
        if self.vector_store_path:
            self.vectorstore.save_local(str(self.vector_store_path))
        
        if self.verbose:
            print("âœ… ë²¡í„° DB ì¬êµ¬ì¶• ì™„ë£Œ")


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    from pathlib import Path
    
    project_root = Path(__file__).parent.parent.parent
    pdf_path = project_root / "prod1_menual.pdf"
    vector_store_path = project_root / "web" / "vector_store"
    
    if not pdf_path.exists():
        print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        exit(1)
    
    # RAG ë§¤ë‹ˆì € ì´ˆê¸°í™”
    rag = RAGManager(
        pdf_path=pdf_path,
        vector_store_path=vector_store_path,
        verbose=True
    )
    
    # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n=== ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")
    results = rag.search_defect_manual(
        product="prod1",
        defect_en="burr",
        keywords=["burr", "ë²„", "ë‚ ê°œ"]
    )
    
    print("\n[ë°œìƒ ì›ì¸]")
    for i, cause in enumerate(results["ì›ì¸"], 1):
        print(f"{i}. {cause[:100]}...")
    
    print("\n[ì¡°ì¹˜ ê°€ì´ë“œ]")
    for i, action in enumerate(results["ì¡°ì¹˜"], 1):
        print(f"{i}. {action[:100]}...")