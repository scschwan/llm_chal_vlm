"""
RAG (Retrieval-Augmented Generation) ë§¤ë‹ˆì €
LangChain ê¸°ë°˜ PDF ë§¤ë‰´ì–¼ ê²€ìƒ‰
"""

from __future__ import annotations
from pathlib import Path
from typing import List, Dict, Optional
import re

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS


class RAGManager:
    """PDF ë§¤ë‰´ì–¼ RAG ê´€ë¦¬ì"""
    
    def __init__(
        self,
        pdf_path: str | Path,
        embedding_model: str = "jhgan/ko-sbert-nli",
        vector_store_path: Optional[str | Path] = None,
        device: str = "cuda",
        verbose: bool = True
    ):
        self.pdf_path = Path(pdf_path)
        self.vector_store_path = Path(vector_store_path) if vector_store_path else None
        self.device = device
        self.verbose = verbose
        
        if self.verbose:
            print(f"ğŸ”¤ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {embedding_model}")
        
        self.embeddings = HuggingFaceEmbeddings(
            model_name=embedding_model,
            model_kwargs={'device': self.device}
        )
        
        self.vectorstore = self._load_or_build_vectorstore()
        
        if self.verbose:
            print("âœ… RAG ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_or_build_vectorstore(self) -> FAISS:
        """ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ë˜ëŠ” êµ¬ì¶•"""
        if self.vector_store_path and self.vector_store_path.exists():
            index_file = self.vector_store_path / "index.faiss"
            if index_file.exists():
                if self.verbose:
                    print(f"ğŸ“‚ ë²¡í„° DB ë¡œë“œ ì¤‘: {self.vector_store_path}")
                
                try:
                    return FAISS.load_local(
                        str(self.vector_store_path),
                        self.embeddings,
                        allow_dangerous_deserialization=True
                    )
                except Exception as e:
                    if self.verbose:
                        print(f"âš ï¸  ë²¡í„° DB ë¡œë“œ ì‹¤íŒ¨: {e}")
                        print("   ìƒˆë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤...")
        
        if self.verbose:
            print(f"ğŸ“š PDF ë¬¸ì„œ ë¡œë“œ ì¤‘: {self.pdf_path}")
        
        loader = PyPDFLoader(str(self.pdf_path))
        documents = loader.load()
        
        if self.verbose:
            print(f"   ë¡œë“œëœ í˜ì´ì§€ ìˆ˜: {len(documents)}")
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ".", " ", ""]
        )
        texts = text_splitter.split_documents(documents)
        
        if self.verbose:
            print(f"   ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(texts)}")
        
        if self.verbose:
            print("ğŸ”¨ ë²¡í„° DB êµ¬ì¶• ì¤‘...")
        
        vectorstore = FAISS.from_documents(texts, self.embeddings)
        
        if self.vector_store_path:
            self.vector_store_path.mkdir(parents=True, exist_ok=True)
            vectorstore.save_local(str(self.vector_store_path))
            
            if self.verbose:
                print(f"âœ… ë²¡í„° DB ì €ì¥ ì™„ë£Œ: {self.vector_store_path}")
        
        return vectorstore
    
    def search_defect_manual(
        self,
        product: str,
        defect_en: str,
        keywords: List[str],
        top_k: int = 3
    ) -> Dict[str, List[str]]:
        """ë¶ˆëŸ‰ ë§¤ë‰´ì–¼ ê²€ìƒ‰ (ì›ì¸/ì¡°ì¹˜ ë¶„ë¦¬)"""
        
        query = " ".join(keywords)
        if self.verbose:
            print(f"ğŸ” ë§¤ë‰´ì–¼ ê²€ìƒ‰: {query}")
        
        # ë²¡í„° ê²€ìƒ‰
        results = self.vectorstore.similarity_search(query, k=10)
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        full_text = "\n\n".join([doc.page_content for doc in results])
        
        # í•´ë‹¹ ë¶ˆëŸ‰ ì„¹ì…˜ ì°¾ê¸°
        defect_pattern = rf'{defect_en}\s*\([^)]+\)(.*?)(?=(?:burr|hole|scratch|Scratch)\s*\(|$)'
        match = re.search(defect_pattern, full_text, re.IGNORECASE | re.DOTALL)
        
        if not match:
            if self.verbose:
                print(f"   âš ï¸ {defect_en} ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return {"ì›ì¸": [], "ì¡°ì¹˜": []}
        
        section = match.group(1)
        
        # ì›ì¸ ì¶”ì¶œ
        causes = []
        cause_match = re.search(r'ë°œìƒ\s*ì›ì¸(.*?)ì¡°ì¹˜\s*ê°€ì´ë“œ', section, re.DOTALL)
        if cause_match:
            cause_text = cause_match.group(1)
            causes = [
                line.strip().lstrip('â€¢-').strip()
                for line in cause_text.split('\n')
                if line.strip() and (line.strip().startswith('â€¢') or line.strip().startswith('-'))
            ]
        
        # ì¡°ì¹˜ ì¶”ì¶œ
        actions = []
        action_match = re.search(r'ì¡°ì¹˜\s*ê°€ì´ë“œ(.*?)(?:ìš”ì•½|$)', section, re.DOTALL)
        if action_match:
            action_text = action_match.group(1)
            actions = [
                line.strip().lstrip('â€¢-').strip()
                for line in action_text.split('\n')
                if line.strip() and (line.strip().startswith('â€¢') or line.strip().startswith('-'))
            ]
        
        causes = causes[:top_k]
        actions = actions[:top_k]
        
        if self.verbose:
            print(f"   ì¶”ì¶œ: ì›ì¸ {len(causes)}ê°œ, ì¡°ì¹˜ {len(actions)}ê°œ")
        
        return {
            "ì›ì¸": causes,
            "ì¡°ì¹˜": actions
        }


if __name__ == "__main__":
    from pathlib import Path
    
    project_root = Path(__file__).parent.parent.parent
    pdf_path = project_root / "manual_store" / "prod1_menual.pdf"
    vector_store_path = project_root / "manual_store"
    
    if not pdf_path.exists():
        print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        exit(1)
    
    rag = RAGManager(
        pdf_path=pdf_path,
        vector_store_path=vector_store_path,
        verbose=True
    )
    
    print("\n=== ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")
    results = rag.search_defect_manual(
        product="prod1",
        defect_en="hole",
        keywords=["hole", "ê¸°ê³µ"]
    )
    
    print(f"\n[ë°œìƒ ì›ì¸] {len(results['ì›ì¸'])}ê°œ")
    for i, cause in enumerate(results["ì›ì¸"], 1):
        print(f"{i}. {cause}")
    
    print(f"\n[ì¡°ì¹˜ ê°€ì´ë“œ] {len(results['ì¡°ì¹˜'])}ê°œ")
    for i, action in enumerate(results["ì¡°ì¹˜"], 1):
        print(f"{i}. {action}")