"""
RAG (Retrieval-Augmented Generation) ë§¤ë‹ˆì €
LangChain ê¸°ë°˜ PDF ë§¤ë‰´ì–¼ ê²€ìƒ‰
"""

from __future__ import annotations
from pathlib import Path
from typing import List, Dict, Optional

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
import re


class RAGManager:
    """PDF ë§¤ë‰´ì–¼ RAG ê´€ë¦¬ì"""
    
    def __init__(
        self,
        pdf_path: str | Path,
        embedding_model: str = "jhgan/ko-sbert-nli",
        vector_store_path: Optional[str | Path] = None,
        device: str = "cuda",
        verbose: bool = True
    ):
        self.pdf_path = Path(pdf_path)
        self.vector_store_path = Path(vector_store_path) if vector_store_path else None
        self.device = device
        self.verbose = verbose
        
        if self.verbose:
            print(f"ğŸ”¤ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {embedding_model}")
        
        self.embeddings = HuggingFaceEmbeddings(
            model_name=embedding_model,
            model_kwargs={'device': self.device}
        )
        
        self.vectorstore = self._load_or_build_vectorstore()
        
        if self.verbose:
            print("âœ… RAG ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_or_build_vectorstore(self) -> FAISS:
        """ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ë˜ëŠ” êµ¬ì¶•"""
        # ê¸°ì¡´ ë²¡í„° DB ë¡œë“œ ì‹œë„
        if self.vector_store_path and self.vector_store_path.exists():
            index_file = self.vector_store_path / "index.faiss"
            if index_file.exists():
                if self.verbose:
                    print(f"ğŸ“‚ ë²¡í„° DB ë¡œë“œ ì¤‘: {self.vector_store_path}")
                
                try:
                    return FAISS.load_local(
                        str(self.vector_store_path),
                        self.embeddings,
                        allow_dangerous_deserialization=True
                    )
                except Exception as e:
                    if self.verbose:
                        print(f"âš ï¸  ë²¡í„° DB ë¡œë“œ ì‹¤íŒ¨: {e}")
                        print("   ìƒˆë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤...")
        
        # ìƒˆë¡œ êµ¬ì¶•
        if self.verbose:
            print(f"ğŸ“š PDF ë¬¸ì„œ ë¡œë“œ ì¤‘: {self.pdf_path}")
        
        loader = PyPDFLoader(str(self.pdf_path))
        documents = loader.load()
        
        if self.verbose:
            print(f"   ë¡œë“œëœ í˜ì´ì§€ ìˆ˜: {len(documents)}")
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ".", " ", ""]
        )
        texts = text_splitter.split_documents(documents)
        
        if self.verbose:
            print(f"   ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(texts)}")
        
        if self.verbose:
            print("ğŸ”¨ ë²¡í„° DB êµ¬ì¶• ì¤‘...")
        
        vectorstore = FAISS.from_documents(texts, self.embeddings)
        
        if self.vector_store_path:
            self.vector_store_path.mkdir(parents=True, exist_ok=True)
            vectorstore.save_local(str(self.vector_store_path))
            
            if self.verbose:
                print(f"âœ… ë²¡í„° DB ì €ì¥ ì™„ë£Œ: {self.vector_store_path}")
        
        return vectorstore
    
    def search_defect_manual(
        self,
        product: str,
        defect_en: str,
        keywords: List[str],
        top_k: int = 3
    ) -> Dict[str, List[str]]:
        """ë¶ˆëŸ‰ ë§¤ë‰´ì–¼ ê²€ìƒ‰ - ì™„ì „ ì¬ì‘ì„±"""
        
        query = " ".join(keywords)
        
        if self.verbose:
            print(f"ğŸ” ë§¤ë‰´ì–¼ ê²€ìƒ‰: {query}")
        
        # 1. ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì²­í¬ ê°€ì ¸ì˜¤ê¸°
        results = self.vectorstore.similarity_search(query, k=top_k * 3)
        
        if self.verbose:
            print(f"   ê²€ìƒ‰ëœ ì²­í¬: {len(results)}ê°œ")
        
        # 2. ë¶ˆëŸ‰ë³„ë¡œ ì›ì¸/ì¡°ì¹˜ ë¶„ë¦¬
        causes = []
        actions = []
        
        for doc in results:
            content = doc.page_content
            
            # í•´ë‹¹ ë¶ˆëŸ‰(defect_en) í¬í•¨ ì—¬ë¶€ í™•ì¸
            if defect_en.lower() not in content.lower():
                continue
            
            # "ë°œìƒ ì›ì¸" ì„¹ì…˜ ì¶”ì¶œ
            if "ë°œìƒ ì›ì¸" in content:
                # "ë°œìƒ ì›ì¸"ë¶€í„° "ì¡°ì¹˜ ê°€ì´ë“œ" ì „ê¹Œì§€
                
                cause_match = re.search(
                    r'ë°œìƒ ì›ì¸\s*(.*?)(?:ì¡°ì¹˜ ê°€ì´ë“œ|burr|Scratch|$)',
                    content,
                    re.DOTALL
                )
                if cause_match:
                    cause_text = cause_match.group(1).strip()
                    # ë¶ˆë¦¿ í¬ì¸íŠ¸ë§Œ ì¶”ì¶œ
                    cause_lines = [
                        line.strip().lstrip('â€¢').strip()
                        for line in cause_text.split('\n')
                        if line.strip().startswith('â€¢')
                    ]
                    causes.extend(cause_lines)
            
            # "ì¡°ì¹˜ ê°€ì´ë“œ" ì„¹ì…˜ ì¶”ì¶œ
            if "ì¡°ì¹˜ ê°€ì´ë“œ" in content or "ì¡°ì¹˜" in content:
                action_match = re.search(
                    r'ì¡°ì¹˜\s*ê°€ì´ë“œ\s*(.*?)(?:burr|Scratch|ë°œìƒ ì›ì¸|$)',
                    content,
                    re.DOTALL
                )
                if action_match:
                    action_text = action_match.group(1).strip()
                    action_lines = [
                        line.strip().lstrip('â€¢').strip()
                        for line in action_text.split('\n')
                        if line.strip().startswith('â€¢')
                    ]
                    actions.extend(action_lines)
        
        # 3. ì¤‘ë³µ ì œê±° ë° ê°œìˆ˜ ì œí•œ
        causes = list(dict.fromkeys(causes))[:top_k]
        actions = list(dict.fromkeys(actions))[:top_k]
        
        if self.verbose:
            print(f"   ì¶”ì¶œ: ì›ì¸ {len(causes)}ê°œ, ì¡°ì¹˜ {len(actions)}ê°œ")
        
        return {
            "ì›ì¸": causes,
            "ì¡°ì¹˜": actions
        }


if __name__ == "__main__":
    from pathlib import Path
    
    project_root = Path(__file__).parent.parent.parent
    pdf_path = project_root / "manual_store" / "prod1_menual.pdf"
    vector_store_path = project_root / "manual_store"
    
    if not pdf_path.exists():
        print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        exit(1)
    
    rag = RAGManager(
        pdf_path=pdf_path,
        vector_store_path=vector_store_path,
        verbose=True
    )
    
    print("\n=== ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")
    results = rag.search_defect_manual(
        product="prod1",
        defect_en="burr",
        keywords=["burr", "ë²„", "ë‚ ê°œ"]
    )
    
    print(f"\n[ë°œìƒ ì›ì¸] {len(results['ì›ì¸'])}ê°œ")
    for i, cause in enumerate(results["ì›ì¸"], 1):
        print(f"{i}. {cause[:100]}...")
    
    print(f"\n[ì¡°ì¹˜ ê°€ì´ë“œ] {len(results['ì¡°ì¹˜'])}ê°œ")
    for i, action in enumerate(results["ì¡°ì¹˜"], 1):
        print(f"{i}. {action[:100]}...")