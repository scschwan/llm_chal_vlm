"""
RAG (Retrieval-Augmented Generation) ë§¤ë‹ˆì €
LangChain ê¸°ë°˜ PDF ë§¤ë‰´ì–¼ ê²€ìƒ‰
"""

from __future__ import annotations
from pathlib import Path
from typing import List, Dict, Optional

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS


class RAGManager:
    """PDF ë§¤ë‰´ì–¼ RAG ê´€ë¦¬ì"""
    
    def __init__(
        self,
        pdf_path: str | Path,
        embedding_model: str = "jhgan/ko-sbert-nli",
        vector_store_path: Optional[str | Path] = None,
        device: str = "cuda",
        verbose: bool = True
    ):
        self.pdf_path = Path(pdf_path)
        self.vector_store_path = Path(vector_store_path) if vector_store_path else None
        self.device = device
        self.verbose = verbose
        
        if self.verbose:
            print(f"ğŸ”¤ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {embedding_model}")
        
        self.embeddings = HuggingFaceEmbeddings(
            model_name=embedding_model,
            model_kwargs={'device': self.device}
        )
        
        self.vectorstore = self._load_or_build_vectorstore()
        
        if self.verbose:
            print("âœ… RAG ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_or_build_vectorstore(self) -> FAISS:
        """ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ë˜ëŠ” êµ¬ì¶•"""
        # ê¸°ì¡´ ë²¡í„° DB ë¡œë“œ ì‹œë„
        if self.vector_store_path and self.vector_store_path.exists():
            index_file = self.vector_store_path / "index.faiss"
            if index_file.exists():
                if self.verbose:
                    print(f"ğŸ“‚ ë²¡í„° DB ë¡œë“œ ì¤‘: {self.vector_store_path}")
                
                try:
                    return FAISS.load_local(
                        str(self.vector_store_path),
                        self.embeddings,
                        allow_dangerous_deserialization=True
                    )
                except Exception as e:
                    if self.verbose:
                        print(f"âš ï¸  ë²¡í„° DB ë¡œë“œ ì‹¤íŒ¨: {e}")
                        print("   ìƒˆë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤...")
        
        # ìƒˆë¡œ êµ¬ì¶•
        if self.verbose:
            print(f"ğŸ“š PDF ë¬¸ì„œ ë¡œë“œ ì¤‘: {self.pdf_path}")
        
        loader = PyPDFLoader(str(self.pdf_path))
        documents = loader.load()
        
        if self.verbose:
            print(f"   ë¡œë“œëœ í˜ì´ì§€ ìˆ˜: {len(documents)}")
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ".", " ", ""]
        )
        texts = text_splitter.split_documents(documents)
        
        if self.verbose:
            print(f"   ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(texts)}")
        
        if self.verbose:
            print("ğŸ”¨ ë²¡í„° DB êµ¬ì¶• ì¤‘...")
        
        vectorstore = FAISS.from_documents(texts, self.embeddings)
        
        if self.vector_store_path:
            self.vector_store_path.mkdir(parents=True, exist_ok=True)
            vectorstore.save_local(str(self.vector_store_path))
            
            if self.verbose:
                print(f"âœ… ë²¡í„° DB ì €ì¥ ì™„ë£Œ: {self.vector_store_path}")
        
        return vectorstore
    
    def search_defect_manual(
        self,
        product: str,
        defect_en: str,
        keywords: List[str],
        top_k: int = 3
    ) -> Dict[str, List[str]]:
        """ë¶ˆëŸ‰ ë§¤ë‰´ì–¼ ê²€ìƒ‰"""
        query = " ".join(keywords)
        
        if self.verbose:
            print(f"ğŸ” ë§¤ë‰´ì–¼ ê²€ìƒ‰: {query}")
        
        results = self.vectorstore.similarity_search(query, k=top_k * 2)
        
        # ëª¨ë“  ê²°ê³¼ë¥¼ ì›ì¸/ì¡°ì¹˜ë¡œ ë‚˜ëˆ” (ë©”íƒ€ë°ì´í„° ì—†ì´)
        all_results = [doc.page_content for doc in results]
        
        # ê°„ë‹¨íˆ ì ˆë°˜ì”© ë‚˜ëˆ” (ë˜ëŠ” ì „ë¶€ ì›ì¸ê³¼ ì¡°ì¹˜ ëª¨ë‘ì— í¬í•¨)
        mid = len(all_results) // 2
        
        return {
            "ì›ì¸": all_results[:top_k],
            "ì¡°ì¹˜": all_results[top_k:top_k*2] if len(all_results) > top_k else all_results
        }


if __name__ == "__main__":
    from pathlib import Path
    
    project_root = Path(__file__).parent.parent.parent
    pdf_path = project_root / "manual_store" / "prod1_menual.pdf"
    vector_store_path = project_root / "manual_store"
    
    if not pdf_path.exists():
        print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        exit(1)
    
    rag = RAGManager(
        pdf_path=pdf_path,
        vector_store_path=vector_store_path,
        verbose=True
    )
    
    print("\n=== ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")
    results = rag.search_defect_manual(
        product="prod1",
        defect_en="burr",
        keywords=["burr", "ë²„", "ë‚ ê°œ"]
    )
    
    print(f"\n[ë°œìƒ ì›ì¸] {len(results['ì›ì¸'])}ê°œ")
    for i, cause in enumerate(results["ì›ì¸"], 1):
        print(f"{i}. {cause[:100]}...")
    
    print(f"\n[ì¡°ì¹˜ ê°€ì´ë“œ] {len(results['ì¡°ì¹˜'])}ê°œ")
    for i, action in enumerate(results["ì¡°ì¹˜"], 1):
        print(f"{i}. {action[:100]}...")